AWSTemplateFormatVersion: '2010-09-09'
Parameters:
  BucketName:
    Type: String
    Description: Name for the bucket  
  PrefixPlaceholder:
    Description: Prefix for the S3 key filter
    Type: String
  SuffixPlaceholder:
    Description: Suffix for the S3 key filter
    Type: String
    Default: ".json" 
  snstopicname:
    Description: name of sns topic
    Type: String
  snsemail:
    Description: email id
    Type: String
  lambdafunctionname:
    Description: name of lambda function
    Type: String
  pythonruntime:
    Description: eg python3.12
    Type: String
  pandaslayerversion:
    Description: pandas layer version
    Type: String
  lambdarolename:
    Description: name of lambda role
    Type: String
Resources:
  # Lambda Execution Role resource definition
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Ref lambdarolename
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:GetLogEvents
                Resource: arn:aws:logs:*:*:*
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource: !Sub "arn:aws:s3:::${BucketName}/*"
              - Effect: Allow
                Action: 
                  - sns:Publish
                Resource: !GetAtt MyJsonToParquetTopic.TopicArn
  # create bucket
  MyJsonParquetBucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref BucketName
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: 's3:ObjectCreated:Put'
            Filter:
              S3Key:
                Rules:
                  - Name: prefix
                    Value: !Ref PrefixPlaceholder
                  - Name: suffix
                    Value: !Ref SuffixPlaceholder
            Function: !GetAtt MyLambdaFunction.Arn
  # s3 permission
  s3Permission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt MyLambdaFunction.Arn
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub "arn:aws:s3:::${BucketName}"
  # sns
  MyJsonToParquetTopic:
    Type: 'AWS::SNS::Topic'
    Properties:
      TopicName: !Ref snstopicname
      Subscription:
        - Endpoint: !Ref snsemail
          Protocol: email
  # Lambda Function
  MyLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Ref lambdafunctionname
      Code:
        ZipFile: |
          import json
          import pandas as pd
          import boto3
          import logging
          from io import BytesIO

          # Configure logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              s3 = boto3.client('s3')
              sns = boto3.client('sns')

              try:
                  region = boto3.session.Session().region_name
                  account_id = boto3.client('sts').get_caller_identity().get('Account')
                  topic_arn = f"arn:aws:sns:{region}:{account_id}:notify"

                  # Get the file content from the event
                  bucket_name = event['Records'][0]['s3']['bucket']['name']
                  json_file_key = event['Records'][0]['s3']['object']['key']

                  # Log bucket and file information
                  logger.info(f"Processing JSON file: s3://{bucket_name}/{json_file_key}")

                  # Get the JSON file from S3
                  response = s3.get_object(Bucket=bucket_name, Key=json_file_key)
                  json_content = response['Body'].read()

                  # Convert JSON content to a pandas DataFrame
                  json_data = json.loads(json_content)
                  df = pd.DataFrame(json_data)

                  # Convert DataFrame to Parquet in-memory
                  parquet_buffer = BytesIO()
                  df.to_parquet(parquet_buffer, index=False)

                  # Define the target Parquet file key
                  parquet_file_key = json_file_key.rsplit('.', 1)[0] + '.parquet'

                  # Upload the Parquet file back to S3
                  s3.put_object(Bucket=bucket_name, Key=parquet_file_key, Body=parquet_buffer.getvalue())

                  # Log successful conversion
                  logger.info(f"Parquet conversion successful. Parquet file saved at s3://{bucket_name}/{parquet_file_key}")

                  # Get recent log events
                  log_events = get_lambda_logs(context)

                  # Publish message to SNS topic
                  response = sns.publish(
                      TopicArn=topic_arn,
                      Message=f'Parquet conversion successful for file: s3://{bucket_name}/{json_file_key}\n\nLogs:\n{log_events}'
                  )

                  return {
                      'statusCode': 200,
                      'body': json.dumps('Parquet conversion successful')
                  }

              except Exception as e:
                  # Log error message
                  logger.error(f"Error converting JSON to Parquet: {e}")

                  # Publish error message to SNS topic
                  response = sns.publish(
                      TopicArn=topic_arn,
                      Message=f'Error converting JSON to Parquet for file: s3://{bucket_name}/{json_file_key}\n\nError: {str(e)}'
                  )

                  return {
                      'statusCode': 500,
                      'body': json.dumps(f'Error: {str(e)}')
                  }

          def get_lambda_logs(context):
              logs_client = boto3.client('logs')
              log_group_name = context.log_group_name
              log_stream_name = context.log_stream_name

              response = logs_client.get_log_events(
                  logGroupName=log_group_name,
                  logStreamName=log_stream_name,
                  limit=10  # Adjust limit as needed
              )

              log_events = [event['message'] for event in response['events']]
              return '\n'.join(log_events)
      Handler: index.lambda_handler
      Layers:
        - !Sub "arn:aws:lambda:${AWS::Region}:336392948345:layer:AWSSDKPandas-Python312:${pandaslayerversion}"
        
      Runtime: !Ref pythonruntime
      Timeout: 60
      MemorySize: 256
      Role: !GetAtt LambdaExecutionRole.Arn
# Outputs
Outputs:
  SnsTopicArn:
    Description: SNS Topic ARN
    Value: !Ref MyJsonToParquetTopic
